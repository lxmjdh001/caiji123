#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
æµ‹è¯•æ¨èé˜…è¯»åŠŸèƒ½
"""

from database import Database
from scraper import WeChatScraper

def test_recommend_function():
    """æµ‹è¯•æ¨èé˜…è¯»åŠŸèƒ½"""
    print("ğŸ§ª æµ‹è¯•æ¨èé˜…è¯»åŠŸèƒ½")
    print("=" * 50)
    
    # åˆå§‹åŒ–æ•°æ®åº“å’Œé‡‡é›†å™¨
    db = Database("test.db")
    scraper = WeChatScraper()
    
    # æ·»åŠ ä¸€äº›æµ‹è¯•æ–‡ç« åˆ°æ•°æ®åº“
    test_articles = [
        {
            'title': 'åŠ æ‹¿å¤§ç§»æ°‘æ”¿ç­–æœ€æ–°è§£è¯»',
            'author': 'ç§»æ°‘ä¸“å®¶',
            'content': 'è¿™æ˜¯å…³äºåŠ æ‹¿å¤§ç§»æ°‘æ”¿ç­–çš„è¯¦ç»†è§£è¯»...',
            'url': 'https://mp.weixin.qq.com/s/test1',
            'scrape_time': '2025-09-12 10:00:00',
            'word_count': 1500
        },
        {
            'title': 'ç•™å­¦åŠ æ‹¿å¤§å¿…çŸ¥çš„10ä¸ªè¦ç‚¹',
            'author': 'ç•™å­¦é¡¾é—®',
            'content': 'ç•™å­¦åŠ æ‹¿å¤§éœ€è¦æ³¨æ„çš„è¦ç‚¹...',
            'url': 'https://mp.weixin.qq.com/s/test2',
            'scrape_time': '2025-09-12 11:00:00',
            'word_count': 1200
        },
        {
            'title': 'åŠ æ‹¿å¤§ç”Ÿæ´»æˆæœ¬åˆ†æ',
            'author': 'ç”Ÿæ´»è¾¾äºº',
            'content': 'è¯¦ç»†åˆ†æåŠ æ‹¿å¤§çš„ç”Ÿæ´»æˆæœ¬...',
            'url': 'https://mp.weixin.qq.com/s/test3',
            'scrape_time': '2025-09-12 12:00:00',
            'word_count': 1800
        }
    ]
    
    # æ·»åŠ æµ‹è¯•æ–‡ç« åˆ°æ•°æ®åº“
    for article in test_articles:
        db.add_article(article)
        print(f"âœ… æ·»åŠ æµ‹è¯•æ–‡ç« : {article['title']}")
    
    # æµ‹è¯•è·å–æ¨èæ–‡ç« 
    recommended_articles = db.get_random_articles(15)
    print(f"\nğŸ“š è·å–åˆ° {len(recommended_articles)} ç¯‡æ¨èæ–‡ç« :")
    for article in recommended_articles:
        print(f"  - {article['title']} ({article['author']})")
    
    # æµ‹è¯•ç”Ÿæˆå¸¦æ¨èé˜…è¯»çš„HTML
    test_data = {
        'title': 'æµ‹è¯•æ–‡ç« æ ‡é¢˜',
        'author': 'æµ‹è¯•ä½œè€…',
        'content': 'è¿™æ˜¯æµ‹è¯•æ–‡ç« çš„å†…å®¹...',
        'scrape_time': '2025-09-12 13:00:00',
        'word_count': 1000
    }
    
    html_content = scraper.generate_html(test_data, recommended_articles)
    
    # ä¿å­˜æµ‹è¯•HTML
    with open('test_recommend.html', 'w', encoding='utf-8') as f:
        f.write(html_content)
    
    print(f"\nâœ… æµ‹è¯•HTMLå·²ç”Ÿæˆ: test_recommend.html")
    print("ğŸ‰ æ¨èé˜…è¯»åŠŸèƒ½æµ‹è¯•å®Œæˆï¼")

if __name__ == "__main__":
    test_recommend_function()
