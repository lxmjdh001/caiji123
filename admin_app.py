#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
ç®¡ç†ç•Œé¢åº”ç”¨
"""

from flask import Flask, render_template, request, jsonify, redirect, url_for
import threading
import time
import os
from datetime import datetime
from database import Database
from auto_scraper import AutoScraper

# è·å–å½“å‰æ–‡ä»¶çš„ç›®å½•
current_dir = os.path.dirname(os.path.abspath(__file__))
template_dir = os.path.join(current_dir, 'templates')

app = Flask(__name__, template_folder=template_dir)

# å…¨å±€å˜é‡
auto_scraper = AutoScraper()
scraping_status = {
    'is_running': False,
    'keywords': [],
    'interval_hours': 6,
    'max_articles_per_keyword': 5
}

@app.route('/')
def index():
    """ä¸»é¡µ"""
    stats = auto_scraper.get_scraping_status()
    return render_template('admin.html', stats=stats)

@app.route('/api/keywords', methods=['GET'])
def get_keywords():
    """è·å–å…³é”®è¯åˆ—è¡¨"""
    keywords = auto_scraper.db.get_keywords()
    return jsonify(keywords)

@app.route('/api/keywords', methods=['POST'])
def add_keyword():
    """æ·»åŠ å…³é”®è¯"""
    data = request.get_json()
    keyword = data.get('keyword', '').strip()
    
    if not keyword:
        return jsonify({'success': False, 'message': 'è¯·è¾“å…¥å…³é”®è¯'})
    
    try:
        keyword_id = auto_scraper.db.add_keyword(keyword)
        return jsonify({'success': True, 'message': 'å…³é”®è¯æ·»åŠ æˆåŠŸ', 'id': keyword_id})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})

@app.route('/api/keywords/<int:keyword_id>', methods=['DELETE'])
def delete_keyword(keyword_id):
    """åˆ é™¤å…³é”®è¯"""
    try:
        conn = auto_scraper.db.db_path
        # è¿™é‡Œå¯ä»¥æ·»åŠ åˆ é™¤é€»è¾‘
        return jsonify({'success': True, 'message': 'å…³é”®è¯åˆ é™¤æˆåŠŸ'})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})

@app.route('/api/articles')
def get_articles():
    """è·å–æ–‡ç« åˆ—è¡¨"""
    keyword_id = request.args.get('keyword_id', type=int)
    limit = request.args.get('limit', 50, type=int)
    
    articles = auto_scraper.db.get_articles(keyword_id, limit)
    return jsonify(articles)

@app.route('/api/tasks')
def get_tasks():
    """è·å–ä»»åŠ¡åˆ—è¡¨"""
    status = request.args.get('status')
    limit = request.args.get('limit', 50, type=int)
    
    tasks = auto_scraper.db.get_tasks(status, limit)
    return jsonify(tasks)

@app.route('/api/scrape', methods=['POST'])
def manual_scrape():
    """æ‰‹åŠ¨é‡‡é›†"""
    data = request.get_json()
    keyword = data.get('keyword', '').strip()
    max_articles = data.get('max_articles', 5)
    
    if not keyword:
        return jsonify({'success': False, 'message': 'è¯·è¾“å…¥å…³é”®è¯'})
    
    def scrape_async():
        result = auto_scraper.auto_scrape_keyword(keyword, max_articles)
        print(f"æ‰‹åŠ¨é‡‡é›†å®Œæˆ: {result}")
    
    # å¯åŠ¨å¼‚æ­¥ä»»åŠ¡
    thread = threading.Thread(target=scrape_async)
    thread.daemon = True
    thread.start()
    
    return jsonify({'success': True, 'message': 'å¼€å§‹é‡‡é›†ï¼Œè¯·ç¨åæŸ¥çœ‹ç»“æœ'})

@app.route('/api/auto-scraper/start', methods=['POST'])
def start_auto_scraper():
    """å¯åŠ¨è‡ªåŠ¨é‡‡é›†"""
    global scraping_status
    
    if scraping_status['is_running']:
        return jsonify({'success': False, 'message': 'è‡ªåŠ¨é‡‡é›†æœåŠ¡å·²åœ¨è¿è¡Œ'})
    
    data = request.get_json()
    keywords = data.get('keywords', [])
    interval_hours = data.get('interval_hours', 6)
    max_articles_per_keyword = data.get('max_articles_per_keyword', 5)
    
    if not keywords:
        return jsonify({'success': False, 'message': 'è¯·è‡³å°‘æ·»åŠ ä¸€ä¸ªå…³é”®è¯'})
    
    # æ›´æ–°çŠ¶æ€
    scraping_status.update({
        'is_running': True,
        'keywords': keywords,
        'interval_hours': interval_hours,
        'max_articles_per_keyword': max_articles_per_keyword
    })
    
    # å¯åŠ¨è‡ªåŠ¨é‡‡é›†
    result = auto_scraper.start_auto_scraper(keywords, interval_hours, max_articles_per_keyword)
    
    return jsonify(result)

@app.route('/api/auto-scraper/stop', methods=['POST'])
def stop_auto_scraper():
    """åœæ­¢è‡ªåŠ¨é‡‡é›†"""
    global scraping_status
    
    result = auto_scraper.stop_auto_scraper()
    scraping_status['is_running'] = False
    
    return jsonify(result)

@app.route('/api/auto-scraper/settings', methods=['POST'])
def set_auto_scraper_settings():
    """è®¾ç½®è‡ªåŠ¨é‡‡é›†å‚æ•°"""
    data = request.get_json()
    batch_size = data.get('batch_size', 100)
    rest_minutes = data.get('rest_minutes', 5)
    
    try:
        auto_scraper.set_batch_settings(batch_size, rest_minutes)
        return jsonify({'success': True, 'message': f'æ‰¹é‡é‡‡é›†è®¾ç½®å·²æ›´æ–°: æ¯{batch_size}ç¯‡ä¼‘æ¯{rest_minutes}åˆ†é’Ÿ'})
    except Exception as e:
        return jsonify({'success': False, 'message': str(e)})

@app.route('/api/auto-scraper/status')
def get_auto_scraper_status():
    """è·å–è‡ªåŠ¨é‡‡é›†çŠ¶æ€"""
    global scraping_status
    
    status_data = auto_scraper.get_scraping_status()
    status_data.update(scraping_status)
    
    return jsonify(status_data)

@app.route('/api/stats')
def get_stats():
    """è·å–ç»Ÿè®¡ä¿¡æ¯"""
    stats = auto_scraper.db.get_stats()
    return jsonify(stats)

@app.route('/api/download/<filename>')
def download_file(filename):
    """ä¸‹è½½æ–‡ä»¶"""
    try:
        from flask import send_file
        return send_file(filename, as_attachment=True)
    except Exception as e:
        return jsonify({'error': str(e)}), 404

@app.route('/api/view/<filename>')
def view_html(filename):
    """æŸ¥çœ‹HTMLæ–‡ä»¶"""
    try:
        with open(filename, 'r', encoding='utf-8') as f:
            content = f.read()
        return content
    except Exception as e:
        return f"æ–‡ä»¶è¯»å–å¤±è´¥: {str(e)}", 404

if __name__ == '__main__':
    print("ğŸš€ å¯åŠ¨å¾®ä¿¡å…¬ä¼—å·è‡ªåŠ¨é‡‡é›†ç®¡ç†ç³»ç»Ÿ")
    print("ğŸŒ è®¿é—®åœ°å€: http://localhost:5001")
    app.run(host='0.0.0.0', port=5001, debug=False)
